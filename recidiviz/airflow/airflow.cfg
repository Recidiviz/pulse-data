[api]
auth_backend = airflow.api.auth.backend.default

[core]
dags_folder = /home/airflow/gcs/dags
base_log_folder = /home/airflow/gcs/logs
plugins_folder = /home/airflow/gcs/plugins
remote_logging = False
remote_log_conn_id = google_cloud_default
executor = CeleryExecutor
dags_are_paused_at_creation = False
load_examples = False
donot_pickle = True
dagbag_import_timeout = 30
parallelism = 50
dag_concurrency = 25
max_active_runs_per_dag = 25
enable_xcom_pickling = False
sql_alchemy_pool_recycle = 570
store_serialized_dags = False
min_serialized_dag_update_interval = 30

[webserver]
web_server_host = 0.0.0.0
web_server_port = 8080
secret_key = temporary_key
workers = 2
worker_class = sync
expose_config = True
async_dagbag_loader = False
worker_refresh_interval = 60
web_server_worker_timeout = 60

[celery]
celery_app_name = airflow.executors.celery_executor
worker_concurrency = 6
worker_log_server_port = 8793
broker_url = redis://airflow-redis-service.default.svc.cluster.local:6379/0
result_backend = redis://airflow-redis-service.default.svc.cluster.local:6379/0
flower_port = 5555
default_queue = default
ssl_active = False

[email]
email_backend = airflow.contrib.utils.sendgrid.send_email

[smtp]
smtp_host = localhost
smtp_starttls = True
smtp_ssl = False
smtp_user = airflow
smtp_port = 25
smtp_password = airflow
smtp_mail_from = no-reply@cloud.google.com

[scheduler]
dag_dir_list_interval = 100
statsd_on = True
statsd_host = airflow-monitoring-service.default.svc.cluster.local
statsd_port = 8125
statsd_prefix = airflow

[kubernetes]
in_cluster = False

[logging]
donot_modify_handlers = True
