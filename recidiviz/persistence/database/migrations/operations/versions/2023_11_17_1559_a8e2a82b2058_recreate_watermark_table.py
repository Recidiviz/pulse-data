# pylint: skip-file
"""recreate_watermark_table

Revision ID: a8e2a82b2058
Revises: 7b54c03d91dd
Create Date: 2023-11-17 15:59:00.389908

"""
import sqlalchemy as sa
from alembic import op

# revision identifiers, used by Alembic.
revision = "a8e2a82b2058"
down_revision = "7b54c03d91dd"
branch_labels = None
depends_on = None

from sqlalchemy.dialects import postgresql


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "direct_ingest_dataflow_job",
        sa.Column("job_id", sa.String(length=255), nullable=False),
        sa.Column("region_code", sa.String(length=255), nullable=False),
        sa.Column(
            "ingest_instance",
            postgresql.ENUM(
                "PRIMARY", "SECONDARY", name="direct_ingest_instance", create_type=False
            ),
            nullable=False,
        ),
        sa.Column("completion_time", sa.DateTime(), nullable=False),
        sa.Column("is_invalidated", sa.Boolean(), nullable=False),
        sa.PrimaryKeyConstraint("job_id"),
    )
    op.create_index(
        op.f("ix_direct_ingest_dataflow_job_ingest_instance"),
        "direct_ingest_dataflow_job",
        ["ingest_instance"],
        unique=False,
    )
    op.create_index(
        op.f("ix_direct_ingest_dataflow_job_region_code"),
        "direct_ingest_dataflow_job",
        ["region_code"],
        unique=False,
    )

    op.create_table(
        "direct_ingest_dataflow_raw_table_upper_bounds",
        sa.Column("watermark_id", sa.Integer(), nullable=False),
        sa.Column("region_code", sa.String(length=255), nullable=False),
        sa.Column("job_id", sa.String(length=255), nullable=False),
        sa.Column("raw_data_file_tag", sa.String(length=255), nullable=False),
        sa.Column("watermark_datetime", sa.DateTime(timezone=True), nullable=False),
        sa.ForeignKeyConstraint(
            ["job_id"],
            ["direct_ingest_dataflow_job.job_id"],
            name="direct_ingest_dataflow_raw_table_upper_bounds_job_id_fkey",
            initially="DEFERRED",
            deferrable=True,
        ),
        sa.PrimaryKeyConstraint("watermark_id"),
        sa.UniqueConstraint(
            "job_id", "raw_data_file_tag", name="file_tags_unique_within_pipeline"
        ),
    )
    op.create_index(
        op.f("ix_direct_ingest_dataflow_raw_table_upper_bounds_job_id"),
        "direct_ingest_dataflow_raw_table_upper_bounds",
        ["job_id"],
        unique=False,
    )
    op.create_index(
        op.f("ix_direct_ingest_dataflow_raw_table_upper_bounds_raw_data_file_tag"),
        "direct_ingest_dataflow_raw_table_upper_bounds",
        ["raw_data_file_tag"],
        unique=False,
    )
    op.create_index(
        op.f("ix_direct_ingest_dataflow_raw_table_upper_bounds_region_code"),
        "direct_ingest_dataflow_raw_table_upper_bounds",
        ["region_code"],
        unique=False,
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(
        op.f("ix_direct_ingest_dataflow_raw_table_upper_bounds_region_code"),
        table_name="direct_ingest_dataflow_raw_table_upper_bounds",
    )
    op.drop_index(
        op.f("ix_direct_ingest_dataflow_raw_table_upper_bounds_raw_data_file_tag"),
        table_name="direct_ingest_dataflow_raw_table_upper_bounds",
    )
    op.drop_index(
        op.f("ix_direct_ingest_dataflow_raw_table_upper_bounds_job_id"),
        table_name="direct_ingest_dataflow_raw_table_upper_bounds",
    )
    op.drop_table("direct_ingest_dataflow_raw_table_upper_bounds")
    op.drop_index(
        op.f("ix_direct_ingest_dataflow_job_region_code"),
        table_name="direct_ingest_dataflow_job",
    )
    op.drop_index(
        op.f("ix_direct_ingest_dataflow_job_ingest_instance"),
        table_name="direct_ingest_dataflow_job",
    )
    op.drop_table("direct_ingest_dataflow_job")
    # ### end Alembic commands ###
