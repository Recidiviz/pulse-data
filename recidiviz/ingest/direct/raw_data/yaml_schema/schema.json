{
  "$schema": "http://json-schema.org/draft-07/schema",
  "$id": "https://recidiviz.org/raw_data/yaml_schema/schema.json",
  "title": "Recidiviz Raw Data Manifest",
  "description": "Raw data configuration schema.",
  "type": "object",
  "additionalProperties": false,
  "properties": {
    "file_tag": {
      "description": "The file tag / table name that this file will get written to",
      "type": "string"
    },
    "file_description": {
      "description": "Description of the raw data file contents",
      "type": "string"
    },
    "data_classification": {
      "description": "The file tag / table name that this file will get written to",
      "type": "string",
      "enum": ["source", "validation"]
    },
    "primary_key_cols": {
      "description": "A list of columns that constitute the primary key for this file. If empty, this table cannot be used in an ingest view query and a '*_latest' view will not be generated for this table. May be left empty for the purposes of allowing us to quickly upload a new file into BQ and then determine the primary keys by querying BQ.",
      "type": "array",
      "items": {
        "type": "string"
      },
      "uniqueItems": true
    },
    "is_primary_person_table": {
      "description": "True if this is the overall table representing person (JII) information for this region. All other raw data tables containing person-level information should be able to be joined back to this table, either directly or indirectly, via PERSON_EXTERNAL_ID type columns. Each region may only have one raw file marked as is_primary_person_table; this designation may be arbitrary if there are multiple primary tables representing person information, such as if there are multiple source data systems.",
      "type": "boolean"
    },
    "columns": {
      "description": "A list of names and descriptions for each column in a file.",
      "type": "array",
      "items": {
        "type": "object",
        "required": ["name"],
        "additionalProperties": false,
        "properties": {
          "name": {
            "description": "The column name in BigQuery-compatible, normalized form (e.g. punctuation stripped)",
            "type": "string"
          },
          "description": {
            "description": "Describes the column contents - if None, this column cannot be used for ingest, nor will you be able to write a raw data migration involving this column",
            "type": "string"
          },
          "field_type": {
            "description": "Designates the type of data that this column contains",
            "type": "string",
            "enum": [
              "string",
              "datetime",
              "person_external_id",
              "staff_external_id",
              "integer"
            ]
          },
          "external_id_type": {
            "description": "If this column holds an external id field_type, designates which type it is (out of the external types defined in common/constants/state/external_id_types.py).",
            "type": "string"
          },
          "is_primary_for_external_id_type": {
            "description": "True if this column holds external ID information in a primary person table. Should only be set for a column of type PERSON_EXTERNAL_ID or STAFF_EXTERNAL_ID. If true for a column of type PERSON_EXTERNAL_ID, then the table that this column belongs to is an ID type root for that region (Note this does not necessarily mean the table is the is_primary_person_table for the region, since there may be multiple tables that are ID type roots for the region.)",
            "type": "boolean"
          },
          "known_values": {
            "description": "Describes possible enum values for this column if known",
            "type": "array",
            "items": {
              "type": "object",
              "required": ["value"],
              "additionalProperties": false,
              "properties": {
                "value": {
                  "description": "The literal enum value",
                  "type": ["string", "integer", "boolean", "null"]
                },
                "description": {
                  "description": "The description that value maps to",
                  "type": ["string", "null"]
                }
              }
            }
          },
          "is_datetime": {
            "description": "True if a column is a date/time",
            "type": "boolean"
          },
          "is_pii": {
            "description": "True if a column contains Personal Identifiable Information (PII)",
            "type": "boolean"
          },
          "datetime_sql_parsers": {
            "description": "Describes the SQL parsers needed to parse the datetime string appropriately. It should contain the string literal {col_name} and follow the format with the SAFE.PARSE_TIMESTAMP('[insert your time format st]', [some expression w/ {col_name}]). SAFE.PARSE_DATE or SAFE.PARSE_DATETIME can also be used. See recidiviz.ingest.direct.views.direct_ingest_big_query_view_types.DATETIME_COL_NORMALIZATION_TEMPLATE",
            "type": "array",
            "items": { "type": "string" }
          },
          "import_blocking_column_validation_exemptions": {
            "description": "A list of dictionaries representing import-blocking validation types that should be exempted for this column.",
            "type": "array",
            "items": {
              "type": "object",
              "required": ["validation_type", "exemption_reason"],
              "additionalProperties": false,
              "properties": {
                "validation_type": {
                  "description": "Import-blocking validation type to exempt",
                  "type": "string",
                  "enum": [
                    "NONNULL_VALUES",
                    "DATETIME_PARSERS",
                    "KNOWN_VALUES",
                    "EXPECTED_TYPE"
                  ]
                },
                "exemption_reason": {
                  "description": "The reason for the exemption",
                  "type": "string"
                }
              }
            }
          },
          "null_values": {
            "description": "A list of strings that should be treated as NULL values for this column.",
            "type": "array",
            "items": { "type": "string" }
          },
          "update_history": {
            "description": "Stores information about an update made to a column, detailing the date and the type of the update",
            "type": "array",
            "items": {
              "type": "object",
              "required": ["update_type", "update_datetime"],
              "additionalProperties": false,
              "properties": {
                "update_type": {
                  "description": "The type of update made to the column",
                  "type": "string",
                  "enum": ["ADDITION", "DELETION", "RENAME"]
                },
                "update_datetime": {
                  "description": "The ISO-formatted datetime the update was made, including timezone. This property is missing a type because python yaml loader automatically converts it to a datetime object, and the schema validator doesn't recognize the datetime object as 'type': 'object'"
                },
                "previous_value": {
                  "description": "The previous name of the column if the update_type is RENAME",
                  "type": "string"
                }
              }
            }
          }
        }
      },
      "uniqueItems": true
    },
    "table_relationships": {
      "description": "A list of other raw data tables to which this table may be joined, along with valid join logic.",
      "type": "array",
      "items": {
        "type": "object",
        "required": ["foreign_table", "join_logic"],
        "additionalProperties": false,
        "properties": {
          "foreign_table": {
            "description": "The name of the related table in this state's raw data",
            "type": "string"
          },
          "cardinality": {
            "description": "Cardinality of the join. If unspecified, many-to-many is assumed.",
            "type": "string"
          },
          "join_logic": {
            "description": "A list of boolean clauses required for the join. These clauses will be joined together with AND to produce the full join logic.",
            "type": "array",
            "items": {
              "type": "string",
              "pattern": "([^=]+)=([^=]+)"
            }
          },
          "transforms": {
            "description": "A list of dictionaries representing transforms/pre-processing that should be done on columns within this join relationship.",
            "type": "array",
            "items": {
              "type": "object",
              "required": ["column", "transform"],
              "additionalProperties": false,
              "properties": {
                "column": {
                  "description": "The column under transform, formatted as table_name.column_name.",
                  "type": "string"
                },
                "transform": {
                  "description": "The transform to apply, a string including {col_name}.",
                  "type": "string"
                }
              }
            }
          }
        }
      }
    },
    "supplemental_order_by_clause": {
      "description": "An additional string clause that will be added to the ORDER BY list that determines which is the most up-to-date row to pick among all rows that have the same primary key. NOTE: Right now this clause does not have access to the date-normalized version of the columns in datetime_cols,  so must handle its own date parsing logic - if this becomes too cumbersome, we can restructure the query to do  date normalization in a subquery before ordering.",
      "type": "string"
    },
    "encoding": {
      "description": "Most likely string encoding for this file (e.g. UTF-8)",
      "type": "string"
    },
    "separator": {
      "description": "The separator character used to denote columns (e.g. ',' or '|').",
      "type": "string"
    },
    "ignore_quotes": {
      "description": "If true, quoted strings are ignored and separators inside of quotes are treated as column separators. This should be used on any file that has free text fields where the quotes are not escaped and the separator is not common to free text. For example, to handle this row from a pipe separated file that has an open quotation with no close quote: `123|456789|2|He said, \"I will be there.|ASDF`",
      "type": "boolean"
    },
    "custom_line_terminator": {
      "description": "The line terminator character(s) used to denote CSV rows. If None, will default to the Pandas default (any combination of \n and \r).",
      "type": "string"
    },
    "export_lookback_window": {
      "description": "The export lookback window for this file tag, or how much historical data we expect to be included in a typical file for this file tag",
      "type": "string",
      "enum": [
        "FULL_HISTORICAL_LOOKBACK",
        "TWO_MONTH_INCREMENTAL_LOOKBACK",
        "ONE_MONTH_INCREMENTAL_LOOKBACK",
        "TWO_WEEK_INCREMENTAL_LOOKBACK",
        "ONE_WEEK_INCREMENTAL_LOOKBACK",
        "UNKNOWN_INCREMENTAL_LOOKBACK"
      ]
    },
    "no_valid_primary_keys": {
      "description": "If true, means that the primary keys for this raw data file are unstable over time",
      "type": "boolean"
    },
    "infer_columns_from_config": {
      "description": "If true, means that we likely will receive a CSV that does not have a header row and therefore, we will use the columns defined in the config, in the order they are defined in, as the column names. By default, False.",
      "type": "boolean"
    },
    "update_cadence": {
      "description": "The cadence at which we expect to receive this raw data file (e.g. WEEKLY, DAILY, IRREGULAR)",
      "type": "string"
    },
    "is_code_file": {
      "description": "If true, means that this file is a code table (likely does not contain person-level data and may have few day-over-day updates).",
      "type": "boolean"
    },
    "is_chunked_file": {
      "description": "If true, means that this file tag is received in multiple files (chunks) within a given data transfer.",
      "type": "boolean"
    },
    "max_num_unparseable_bytes_per_chunk": {
      "description": "The maximum number of unparseable bytes we will allow this raw file to have in a single 100 mb sample before we throw. In general, we expect this value to be None (i.e. we don't allow unparseable bytes); however, in certain situations, states have not been able to fix unparseable bytes in their dbs so we need to be able to clean them out of files automatically during raw data import. It's per chunk as this is the most un-parseable bytes that we'll allow a ~100 mB sample of the raw file have. In practice, we don't need to worry about being super precise with the number of un-parseable bytes as we are mainly concerned with enforcing a reasonable ceiling (like less than 10k) than we are with strictly monitoring the number of bytes",
      "type": "integer"
    },
    "import_blocking_validation_exemptions": {
      "description": "A list of dictionaries representing import-blocking validation types that should be exempted for this table.",
      "type": "array",
      "items": {
        "type": "object",
        "required": ["validation_type", "exemption_reason"],
        "additionalProperties": false,
        "properties": {
          "validation_type": {
            "description": "Import-blocking validation type to exempt",
            "type": "string",
            "enum": [
              "NONNULL_VALUES",
              "DATETIME_PARSERS",
              "KNOWN_VALUES",
              "EXPECTED_TYPE",
              "STABLE_HISTORICAL_RAW_DATA_COUNTS"
            ]
          },
          "exemption_reason": {
            "description": "The reason for the exemption",
            "type": "string"
          }
        }
      }
    }
  },
  "required": [
    "file_tag",
    "file_description",
    "data_classification",
    "primary_key_cols",
    "columns"
  ],
  "examples": [
    {
      "file_tag": "data_table",
      "file_description": "This file contains data from `data` system about `table`.",
      "data_classification": "source",
      "primary_key_cols": ["ID"],
      "columns": [
        {
          "name": "ID",
          "description": "Primary key for table",
          "is_pii": true
        },
        {
          "name": "Description",
          "description": "Long description for record"
        },
        {
          "name": "Type",
          "description": "Type of record",
          "known_values": [
            {
              "value": "ADD",
              "description": "This record represents an addition"
            },
            {
              "value": "DEL",
              "description": "This record represents a deletion"
            }
          ]
        }
      ]
    }
  ]
}
